```python
"""Thực hành phân loại tin tức (CNN, RNN, LSTM).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1r9wfT4z6yO2epyiAVx1C_Aw3IYtEAqvb

# Phân loại văn bản báo tiếng việt

## Import các thư viện cần dùng
"""
```




    'Thực hành phân loại tin tức (CNN, RNN, LSTM).ipynb\n\nAutomatically generated by Colab.\n\nOriginal file is located at\n    https://colab.research.google.com/drive/1r9wfT4z6yO2epyiAVx1C_Aw3IYtEAqvb\n\n# Phân loại văn bản báo tiếng việt\n\n## Import các thư viện cần dùng\n'




```python
import json
import requests
from pprint import pprint
import re
import string
import random
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm.notebook import tqdm
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.naive_bayes import MultinomialNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from collections import defaultdict
import warnings
import sys
import torch
```


```python
# Kiểm tra GPU có khả dụng không
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
if device.type == 'cpu':
    raise RuntimeError("No GPU found")
```


```python
print(f'Using device: {device}')
```

    Using device: cuda



```python
# Đặt random seed
random.seed(42)
np.random.seed(42)
torch.manual_seed(42)
torch.cuda.manual_seed_all(42)
```


```python
"""## Tiền sử lý dữ liệu

### Tải file json chứa dữ liệu
"""
```




    '## Tiền sử lý dữ liệu\n\n### Tải file json chứa dữ liệu\n'




```python
# URL trực tiếp đến file JSON thô trên GitHub
url = 'https://raw.githubusercontent.com/letangphuquy/AI4E/master/3-ml-crawler/data/news_final.json'
```


```python
# Tải nội dung của file
response = requests.get(url)
```


```python
# Kiểm tra mã trạng thái phản hồi để đảm bảo rằng yêu cầu thành công
if response.status_code == 200:
    try:
        data = response.json()  # Đọc nội dung file JSON

        # Hiển thị phần tử đầu tiên của file JSON
        if isinstance(data, list) and len(data) > 0:
            pprint(json.dumps(data[0], indent=4, ensure_ascii=False))
        else:
            print("Dữ liệu JSON không phải là một danh sách hoặc danh sách trống.")

    except json.JSONDecodeError as e:
        print("JSONDecodeError: Không thể phân tích nội dung JSON.")
        print("Nội dung phản hồi không phải là JSON hợp lệ:")
        print(response.text)  # In ra nội dung phản hồi để kiểm tra
else:
    print(f"Yêu cầu thất bại với mã trạng thái {response.status_code}")
    print("Nội dung phản hồi:", response.text)
```

    ('{\n'
     '    "url": '
     '"https://dantri.com.vn/xa-hoi/thu-tuong-kiem-soat-quyen-luc-trong-xay-dung-va-thuc-thi-phap-luat-20240730132720264.htm",\n'
     '    "title": "Thủ tướng: \\"Kiểm soát quyền lực trong xây dựng và thực thi '
     'pháp luật\\"",\n'
     '    "description": "Theo yêu cầu của Thủ tướng Phạm Minh Chính, các cơ quan '
     'cần phối hợp tạo lập cơ chế vận hành, kiểm soát có hiệu quả, phòng ngừa rủi '
     'ro và kiểm soát quyền lực trong xây dựng, thực thi pháp luật.",\n'
     '    "content": "Yêu cầu này được Thủ tướng Phạm Minh Chính nhấn mạnh khi '
     'phát biểu kết luận Hội nghị trực tuyến toàn quốc quán triệt triển khai một '
     'số Luật, Nghị quyết được Quốc hội tại kỳ họp thứ 7, sáng 30/7. Hội nghị do '
     'Chính phủ phối hợp Ủy ban Thường vụ Quốc hội và các cơ quan liên quan tổ '
     'chức.\\nThủ tướng Phạm Minh Chính nhấn mạnh xây dựng và hoàn thiện thể chế '
     'là một trong 3 đột phá chiến lược, chủ trương lớn của Đảng.\\nTheo ông, thể '
     'chế phù hợp sẽ tạo động lực phát triển, góp phần nâng cao đời sống vật chất, '
     'tinh thần nhân dân. Ngược lại, thể chế không phù hợp sẽ kìm hãm sự phát '
     'triển. Vì vậy, trong xây dựng pháp luật phải lấy người dân làm trung tâm, '
     'chủ thể.\\n[Thủ tướng Phạm Minh Chính phát biểu tại Hội nghị (Ảnh: Đoàn '
     'Bắc).]\\nYêu cầu được người đứng đầu Chính phủ đặt ra là thể chế phải đi '
     'trước mở đường cho đột phá phát triển, phát huy tối đa tiềm năng, sức sáng '
     'tạo, đáp ứng tốt nhu cầu đẩy mạnh công nghiệp hóa, hiện đại hóa và hội nhập '
     'quốc tế.\\nThủ tướng khái quát \\"5 tạo lập\\" của thể chế đối với sự phát '
     'triển nhanh và bền vững của đất nước.\\nMột là tạo lập cơ sở pháp lý để kiến '
     'tạo, phát triển năng lực các chủ thể, phát huy đúng vai trò của từng chủ '
     'thể.\\nHai là tạo lập cơ chế, chính sách huy động và phân bổ mọi nguồn lực '
     'của đất nước hiệu quả, phù hợp đối với các chủ thể trong từng lĩnh vực, từng '
     'cấp, từng ngày.\\nBa là tạo lập \\"sân chơi\\" lành mạnh, bình đẳng, minh '
     'bạch, phù hợp, hiệu quả đối với các chủ thể trong từng lĩnh vực, điều tiết '
     'hài hòa lợi ích phát triển với nhau.\\nBốn là tạo lập khung khổ pháp lý phù '
     'hợp để hội nhập quốc tế hiệu quả cao, bảo đảm lợi ích quốc gia, dân tộc, chủ '
     'động tích cực hội nhập quốc tế sâu rộng, hiệu quả.\\nNăm là tạo lập cơ chế '
     'vận hành, kiểm soát có hiệu quả, khắc phục, phòng ngừa các rủi ro, tiêu cực, '
     'kiểm soát quyền lực trong quá trình xây dựng và thực thi pháp luật.\\nĐể '
     'thực hiện nhiệm vụ này, Thủ tướng yêu cầu thực hiện \\"5 đẩy mạnh\\": Đẩy '
     'mạnh tiến độ, nâng cao chất lượng xây dựng luật theo đúng tiến độ đã đề ra; '
     'Đẩy mạnh tháo gỡ khó khăn, vướng mắc từ thực tiễn; Đẩy mạnh công tác rà '
     'soát, hệ thống hóa và pháp điển hóa; Đẩy mạnh cơ chế phân cấp, phân quyền; '
     'Đẩy mạnh công tác phổ biến, giáo dục pháp luật.\\nVề cách làm, Thủ tướng '
     'nhấn mạnh cần gắn kết chặt chẽ giữa xây dựng pháp luật với tổ chức thi hành '
     'pháp luật; bám sát những yêu cầu, nhiệm vụ cụ thể về triển khai đối với từng '
     'luật, nghị quyết được thông qua.\\nĐặc biệt, theo Thủ tướng, cần tuân thủ '
     'nghiêm Luật Ban hành văn bản quy phạm pháp luật, khẩn trương xây dựng, ban '
     'hành, trình ban hành 121 văn bản quy định chi tiết các luật, nghị quyết được '
     'thông qua tại kỳ họp thứ 7 để kịp thời có hiệu lực cùng với luật, nghị '
     'quyết.\\n[Toàn cảnh Hội nghị (Ảnh: Đoàn Bắc).]\\nĐịnh hướng được Thủ tướng '
     'nhấn mạnh là siết chặt kỷ luật, kỷ cương, đề cao trách nhiệm của người đứng '
     'đầu, phát huy tính chủ động của đội ngũ công chức trong xây dựng pháp '
     'luật.\\nThủ tướng cũng lưu ý cần chủ động rà soát, xử lý các vướng mắc, bất '
     'cập phát sinh, nhất là các bất cập liên quan đến thủ tục hành chính, vướng '
     'mắc.\\nBên cạnh đó, theo người đứng đầu Chính phủ, cần phối hợp chặt chẽ với '
     'Chính phủ, bộ, ngành ngay từ giai đoạn đầu trong công tác xây dựng pháp '
     'luật, để bảo đảm tính khả thi của các quy định trong các dự án luật, nghị '
     'quyết.\\nThủ tướng một lần nữa nhấn mạnh yêu cầu lãnh đạo các bộ, ngành, cơ '
     'quan, địa phương và các cán bộ, công chức được giao nhiệm vụ trong công tác '
     'xây dựng, thực thi pháp luật cần phát huy trách nhiệm cao nhất, làm việc có '
     'cảm xúc với tinh thần vì nước, vì dân, \\"chỉ bàn làm, không bàn lùi\\", '
     'phân công rõ ràng nhưng phối hợp đồng bộ, chặt chẽ, hiệu quả.",\n'
     '    "metadata": {\n'
     '        "cat": "Xã hội",\n'
     '        "subcat": "Chính trị",\n'
     '        "published_date": 1722322680,\n'
     '        "author": "Hoài Thu"\n'
     '    },\n'
     '    "web_news": "dantri"\n'
     '}')



```python
"""### Xem các đầu mục"""
```




    '### Xem các đầu mục'




```python
# Trích xuất các danh mục (categories)
categories = {}
for article in data:
    cat = article['metadata']['cat']
    if not cat in categories:
        categories[cat] = {'cnt': 0, 'subcat': set()}
    categories[cat]['cnt'] += 1
    categories[cat]['subcat'].add(article['metadata']['subcat'])
```


```python
for category, info in categories.items():
    print(f"Category: {category}, Count: {info}")
```

    Category: Xã hội, Count: {'cnt': 328, 'subcat': {'', 'Chính trị', 'Nóng trên mạng', 'Chuyện ngày mới', 'Học tập Bác', 'Giao thông', 'Môi trường', 'Cuộc đời và sự nghiệp của Tổng Bí thư Nguyễn Phú Trọng'}}
    Category: Số hóa, Count: {'cnt': 386, 'subcat': {'Công nghệ', 'Blockchain', 'Kinh nghiệm', 'Data4life 2024', 'Ngày hội Game Việt Nam 2024', 'Tech Awards 2024', 'Sản phẩm', None}}
    Category: Du lịch, Count: {'cnt': 1142, 'subcat': {'', 'Dấu chân', 'Ẩm thực', 'Ngủ ngủ nghỉ nghỉ', 'Tư vấn', 'Khám phá', 'Video - Ảnh', 'Đi đâu chơi đi', 'Món ngon - Điểm đẹp', 'Ảnh', 'Điểm đến', 'Khám phá mùa hè Malaysia', 'Tour hay - Khuyến mại', 'Ăn ăn uống uống', 'Tin tức'}}
    Category: Chính trị, Count: {'cnt': 382, 'subcat': {'', 'Xây dựng đảng', 'Sự kiện', 'Đối ngoại'}}
    Category: Bạn đọc, Count: {'cnt': 376, 'subcat': {'', 'Hồi âm', 'Chia sẻ', 'Bạn đọc nói', 'Thơ'}}
    Category: Nội dung chuyên đề, Count: {'cnt': 404, 'subcat': {''}}
    Category: Kinh doanh, Count: {'cnt': 1402, 'subcat': {'', 'Kinh tế xanh', 'Tư vấn tài chính', 'Chuyển động kinh tế số', 'Doanh nhân', 'Tiền của tôi', 'Bảo hiểm', 'Tài chính', 'ESG - Phát triển bền vững', 'Tiêu dùng', 'Doanh nghiệp', 'Quốc tế', 'eBox', 'Ebank', 'Hàng hóa', 'Đầu tư', 'Vĩ mô', 'Chứng khoán', 'Tiết kiệm điện', 'Thị trường', 'Khởi nghiệp'}}
    Category: Pháp luật, Count: {'cnt': 1176, 'subcat': {'', 'Pháp đình', 'Hồ sơ phá án', 'Tư vấn', 'Hồ sơ vụ án', None, 'Ký sự pháp đình'}}
    Category: Khoa học - Công nghệ, Count: {'cnt': 344, 'subcat': {'', 'Vũ trụ', 'Thế giới tự nhiên', 'Khám phá', 'Khoa học & đời sống'}}
    Category: Bất động sản, Count: {'cnt': 1160, 'subcat': {'', 'Sống xanh', 'Tư vấn', 'Thị trường', 'Chính sách', 'Dự án', 'Nhà đẹp', 'Nhịp sống đô thị', 'Nhà đất', 'Nội thất', None, 'Không gian sống'}}
    Category: Giáo dục, Count: {'cnt': 1118, 'subcat': {'', 'Góc phụ huynh', 'Tài chính lạc quan', 'Du học', 'Khoa học', 'Gương sáng', 'Khuyến học', 'Học tiếng anh', 'Tin tức', 'Ai contest 2024', 'Tuyển sinh', 'Nhà trường', None, 'Giáo dục 4.0', 'Học tiếng Anh', 'Giáo dục - Nghề nghiệp', 'Chân dung', 'Việc làm', 'Thảo luận'}}
    Category: Văn hóa, Count: {'cnt': 294, 'subcat': {'', 'Unesco', 'Mỹ thuật - sân khấu', 'Di sản'}}
    Category: An sinh, Count: {'cnt': 354, 'subcat': {'', 'Chuyển động', 'Chuyện đời', 'Dân sinh'}}
    Category: Thể thao, Count: {'cnt': 1059, 'subcat': {'', 'Các môn khác', 'Tin chuyển nhượng', 'Marathon', 'V-League', 'Video', 'Euro 2024', 'Bóng đá quốc tế', 'Bóng đá', 'Võ thuật - Các môn khác', 'Ngoại hạng Anh', 'Golf', 'Tường thuật', 'EURO 2024', 'Ảnh', 'Euro', 'Bóng đá trong nước', 'Bóng đá Châu Âu', 'Champions League', 'Hậu trường', 'Tennis'}}
    Category: Ô tô - xe máy, Count: {'cnt': 374, 'subcat': {'', 'Giá xe', 'Đánh giá xe', 'Khám phá', 'Xe mới', 'Sau tay lái'}}
    Category: Thông tin và truyền thông, Count: {'cnt': 364, 'subcat': {'', 'Tt&tt địa phương', 'Công nghệ', 'Chuyển đổi số', 'Thị trường', 'Kinh tế số', 'Hạ tầng số', 'An toàn thông tin', 'Toàn văn của bộ trưởng', 'Báo chí - xuất bản'}}
    Category: Giải trí, Count: {'cnt': 1118, 'subcat': {'', 'Sân khấu - Mỹ thuật', 'Sách hay', 'Hạt giống tâm hồn', 'Mỹ thuật - Sân khấu', 'Nhạc', 'Phim', 'Hậu trường', 'Giới sao', 'Thế giới sao', 'Sách', 'Âm nhạc', 'Hoa hậu', 'Truyền hình', 'Điện ảnh', 'Thời trang'}}
    Category: Tình yêu - Giới tính, Count: {'cnt': 399, 'subcat': {'', 'Gia đình', 'Tình yêu', 'Chuyện của tôi'}}
    Category: Thời sự, Count: {'cnt': 809, 'subcat': {'', 'Mekong', 'Lao động - Việc làm', 'Chính trị', 'Quốc hội', 'Giao thông', 'Quốc phòng', 'Môi trường', 'Dân sinh', 'An toàn giao thông', None}}
    Category: Ô tô - Xe máy, Count: {'cnt': 371, 'subcat': {'', 'Kinh nghiệm - Tư vấn', 'Cộng đồng xe', 'Xe điện', 'Thị trường xe', 'Đánh giá'}}
    Category: Sức khỏe, Count: {'cnt': 969, 'subcat': {'', 'Đàn ông', 'Khỏe đẹp', 'Ung thư', 'Tư vấn', 'Vaccine', 'Kiến thức giới tính', 'Các loại bệnh', 'Sống khỏe', 'Tư vấn sức khỏe', 'Thẩm mỹ viện Hồng Ngọc', 'Làm đẹp', 'Dịch vụ y tế quốc tế', 'Các bệnh', 'Sức khỏe chủ động', 'Tin tức', 'Tư vấn mổ mắt công nghệ mới', 'Dinh dưỡng'}}
    Category: Dân tộc thiểu số và miền núi, Count: {'cnt': 388, 'subcat': {''}}
    Category: Đời sống, Count: {'cnt': 1021, 'subcat': {'', 'Chợ online', 'Mẹo vặt', 'Gia đình', 'Sống đẹp', 'Tổ ấm', 'Thượng lưu', 'Tiêu dùng', 'Truyền thông về Bình đẳng giới vùng đồng bào dân tộc thiểu số và miền núi', 'Nhà đẹp', 'Ẩm thực', 'Bài học sống', 'Tư vấn tiết kiệm điện mùa nóng', 'Tâm sự', 'Chuyện lạ', 'Nhà', 'Giới trẻ', 'Nhịp sống', 'Cộng đồng'}}
    Category: Thế giới, Count: {'cnt': 1132, 'subcat': {'', 'Tư liệu', 'Cuộc sống đó đây', 'Quân sự', 'Bầu cử tổng thống Mỹ 2024', 'Việt nam và thế giới', 'Chân dung', 'Hồ sơ', 'Phân tích', 'Người Việt 5 châu', 'Thế giới đó đây', 'Kiều bào', 'Châu Á', 'Phân tích - Bình luận', 'Châu Mỹ', None, 'Bình luận quốc tế'}}
    Category: Xe, Count: {'cnt': 318, 'subcat': {'Diễn đàn', 'Xe điện', 'Thị trường', 'Cầm lái', None}}
    Category: Các bệnh, Count: {'cnt': 184, 'subcat': {'Thần kinh', 'Hiếm muộn', 'Tai mũi họng', 'Ung thư', 'Tiêu hóa', 'Nội tiết', 'Hô hấp', 'Tiết niệu - Nam học', 'Da liễu', 'Nhi - Sơ sinh', 'Sản phụ khoa', 'Tim mạch', 'Cơ xương khớp', 'Dinh dưỡng'}}
    Category: Dân tộc - tôn giáo, Count: {'cnt': 323, 'subcat': {'', 'Multimedia', 'Chính sách', 'Văn hóa', 'Đại đoàn kết'}}
    Category: Sức mạnh số, Count: {'cnt': 354, 'subcat': {'', 'Di động - Viễn thông', 'Cộng đồng mạng', 'Phần mềm - Bảo mật', 'Sản phẩm'}}
    Category: Tuần việt nam, Count: {'cnt': 392, 'subcat': {'', 'Tiêu điểm'}}
    Category: Sách, Count: {'cnt': 112, 'subcat': {''}}
    Category: Khoa học, Count: {'cnt': 361, 'subcat': {'Khoa học trong nước', 'Thế giới tự nhiên', 'Phát minh', 'AI4VN 2024', 'Thường thức', 'Tin tức', None}}
    Category: Nông thôn mới, Count: {'cnt': 401, 'subcat': {''}}
    Category: Thị trường - tiêu dùng, Count: {'cnt': 117, 'subcat': {''}}
    Category: Trang chủ, Count: {'cnt': 21, 'subcat': {'Mẹo tư vấn'}}
    Category: Lao động - Việc làm, Count: {'cnt': 356, 'subcat': {'', 'Chính sách', 'Làm giàu', 'Chuyện nghề', 'Nhân lực mới'}}
    Category: Nhịp sống trẻ, Count: {'cnt': 40, 'subcat': {''}}
    Category: Công nghiệp hỗ trợ, Count: {'cnt': 260, 'subcat': {'', 'Chuyển động doanh nghiệp', 'Phóng sự truyền hình', 'Công nghiệp địa phương', 'Tọa đàm trực tuyến', 'Công nghệ và sản phẩm', 'Chính sách và thị trường'}}
    Category: Bảo vệ người tiêu dùng, Count: {'cnt': 93, 'subcat': {''}}
    Category: Net zero, Count: {'cnt': 18, 'subcat': {'', 'Lối sống', 'Chuyển động doanh nghiệp', 'Tài chính xanh', 'Tầm nhìn xanh'}}
    Category: , Count: {'cnt': 32, 'subcat': {'Marathon', 'Tin tức', 'Giày & Phụ kiện', 'Kinh nghiệm'}}
    Category: Ảnh, Count: {'cnt': 14, 'subcat': {''}}
    Category: Tết 2024, Count: {'cnt': 2, 'subcat': {''}}
    Category: Chuyện tử tế, Count: {'cnt': 1, 'subcat': {''}}



```python
"""### Chuyển đổi đầu mục"""
```




    '### Chuyển đổi đầu mục'




```python
# Từ điển ánh xạ các categories hiện tại về 12 loại
# Một số category khá "broad" do hiện tượng mất cân bằng dữ liệu
categories_include = {
    "Thời sự": ["Chính trị", "Tuần Việt Nam"],
    "Pháp luật": [],
    "Thế giới": [],
    "Kinh tế": ["Kinh doanh", "Bất động sản", "Thị trường tiêu dùng", "Việc làm"],
    "Xã hội": ["Văn hóa", "Dân tộc - tôn giáo", "Nông thôn mới", "Dân tộc thiểu số và miền núi", "Nội dung chuyên đề", "An sinh"],
    "Giáo dục": [],
    "Sức khỏe": [], # Sức khỏe - Y tế
    "Đời sống": ["Bảo vệ người tiêu dùng", "Nhân ái", "Tình yêu"],
    "KHCN": ["Thông tin và truyền thông", "Công nghiệp hỗ trợ", "Khoa học", "Sức mạnh số", "Số hóa", "Khoa học - công nghệ"],
    "Thể thao": [],
    "Giải trí": ["Du lịch"]
}
```


```python
# Lọc và chuyển đổi categories
filtered_data = []
for article in data:
    old_category = article['metadata']['cat']
    if old_category not in categories_include:
        new_category = ""
        for category, subcategories in categories_include.items():
            flag = False
            for subcat in subcategories:
                if subcat in old_category: flag = True; new_category = category
            if flag: break
        if not new_category: continue
        article['metadata']['cat'] = new_category
        filtered_data.append(article)
    else: filtered_data.append(article)
```


```python
# In ra các bài báo sau khi lọc và chuyển đổi categories
print(f"Filtered articles count: {len(filtered_data)}")
# Trích xuất các danh mục (categories)
categories = [article['metadata']['cat'] for article in filtered_data]
```

    Filtered articles count: 17897



```python
# Đếm số lượng từng danh mục
category_counts = {}
for category in categories:
    if category in category_counts:
        category_counts[category] += 1
    else:
        category_counts[category] = 1
```


```python
# Vẽ biểu đồ cột
plt.figure(figsize=(10, 6))  # Điều chỉnh kích thước biểu đồ nhỏ hơn
ax = sns.barplot(x=list(category_counts.keys()), y=list(category_counts.values()))
plt.xlabel('Category')
plt.ylabel('Count')
plt.title('Article Count per Category')
plt.xticks(rotation=45)
```




    ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
     [Text(0, 0, 'Xã hội'),
      Text(1, 0, 'KHCN'),
      Text(2, 0, 'Giải trí'),
      Text(3, 0, 'Thời sự'),
      Text(4, 0, 'Kinh tế'),
      Text(5, 0, 'Pháp luật'),
      Text(6, 0, 'Giáo dục'),
      Text(7, 0, 'Thể thao'),
      Text(8, 0, 'Đời sống'),
      Text(9, 0, 'Sức khỏe'),
      Text(10, 0, 'Thế giới')])




    
![png](th%E1%BB%B1c_h%C3%A0nh_ph%C3%A2n_lo%E1%BA%A1i_tin_t%E1%BB%A9c_%28cnn%2C_rnn%2C_lstm%29_files/th%E1%BB%B1c_h%C3%A0nh_ph%C3%A2n_lo%E1%BA%A1i_tin_t%E1%BB%A9c_%28cnn%2C_rnn%2C_lstm%29_17_1.png)
    



```python
# Thêm số lượng ở trên mỗi cột
for p in ax.patches:
    ax.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='center', xytext=(0, 10), textcoords='offset points')
```


```python
plt.show()
plt.savefig('category-distribution.png')
```


    <Figure size 640x480 with 0 Axes>



```python
# Tạo một defaultdict để lưu các văn bản theo từng category
category_data = defaultdict(list)
for article in filtered_data:
    category_data[article['metadata']['cat']].append(article)
```


```python
# Xác định số lượng mẫu tối đa cho mỗi category
number_sample = 12000
max_samples_per_category = number_sample // len(category_data)
```


```python
# Chọn ngẫu nhiên các mẫu từ mỗi category, giới hạn bởi max_samples_per_category
balanced_data = []
for category, items in category_data.items():
    if len(items) > max_samples_per_category:
        balanced_data.extend(random.sample(items, max_samples_per_category))
    else:
        balanced_data.extend(items)
```


```python
# Nếu số lượng mẫu không đủ number_sample, bổ sung thêm mẫu ngẫu nhiên từ balanced_data
if len(balanced_data) < number_sample:
    additional_samples = random.sample(balanced_data, number_sample - len(balanced_data))
    balanced_data.extend(additional_samples)
```


```python
filtered_data_to_use = balanced_data[:number_sample if number_sample < len(balanced_data) else len(balanced_data)]
print(f"Filtered articles to use count: {len(filtered_data_to_use)}")
```

    Filtered articles to use count: 12000



```python
# Đếm số lượng từng danh mục
category_counts = defaultdict(int)
for item in filtered_data_to_use:
    category_counts[item['metadata']['cat']] += 1
```


```python
# Vẽ biểu đồ cột
plt.figure(figsize=(10, 6))  # Điều chỉnh kích thước biểu đồ nhỏ hơn
ax = sns.barplot(x=list(category_counts.keys()), y=list(category_counts.values()))
plt.xlabel('Category')
plt.ylabel('Count')
plt.title('Article Count per Category')
plt.xticks(rotation=45)
```




    ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
     [Text(0, 0, 'Xã hội'),
      Text(1, 0, 'KHCN'),
      Text(2, 0, 'Giải trí'),
      Text(3, 0, 'Thời sự'),
      Text(4, 0, 'Kinh tế'),
      Text(5, 0, 'Pháp luật'),
      Text(6, 0, 'Giáo dục'),
      Text(7, 0, 'Thể thao'),
      Text(8, 0, 'Đời sống'),
      Text(9, 0, 'Sức khỏe'),
      Text(10, 0, 'Thế giới')])




    
![png](th%E1%BB%B1c_h%C3%A0nh_ph%C3%A2n_lo%E1%BA%A1i_tin_t%E1%BB%A9c_%28cnn%2C_rnn%2C_lstm%29_files/th%E1%BB%B1c_h%C3%A0nh_ph%C3%A2n_lo%E1%BA%A1i_tin_t%E1%BB%A9c_%28cnn%2C_rnn%2C_lstm%29_26_1.png)
    



```python
# Thêm số lượng ở trên mỗi cột
for p in ax.patches:
    ax.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='center', xytext=(0, 10), textcoords='offset points')
```


```python
plt.show()
plt.savefig('balanced-category-distribution.png')
```


    <Figure size 640x480 with 0 Axes>



```python
"""### Làm sạch hơn dữ liệu"""
```




    '### Làm sạch hơn dữ liệu'




```python
# Danh sách stop words tiếng Việt
stop_words = set([
    "bị", "bởi", "cả", "các", "cái", "cần", "càng", "chỉ", "chiếc", "cho", "chứ", "chưa", "chuyện",
    "có", "có_thể", "cứ", "của", "cùng", "cũng", "đã", "đang", "đây", "để", "đến_nỗi", "đều", "điều",
    "do", "đó", "được", "dưới", "gì", "khi", "không", "là", "lại", "lên", "lúc", "mà", "mỗi", "này",
    "nên", "nếu", "ngay", "nhiều", "như", "nhưng", "những", "nơi", "nữa", "phải", "qua", "ra", "rằng",
    "rằng", "rất", "rồi", "sau", "sẽ", "so", "sự", "tại", "theo", "thì", "trên", "trước", "từ", "từng",
    "và", "vẫn", "vào", "vậy", "vì", "việc", "với", "vừa"
])
```


```python
# Trích xuất dữ liệu từ các bài báo đã được lọc
texts = []
labels = []
```


```python
# Lặp qua từng bài báo trong dữ liệu đã lọc
for article in filtered_data_to_use:
    # Kết hợp tiêu đề và nội dung bài báo
    text = article.get('title', '') + ' ' + article.get('description', '') + ' ' + article.get('content', '')
    # Lấy nhãn (category) của bài báo
    label = article['metadata']['cat']
    # Thêm văn bản và nhãn vào danh sách tương ứng
    texts.append(text)
    labels.append(label)
```


```python
# Hàm tiền xử lý văn bản
def preprocess_text(text):
    # Chuyển văn bản thành chữ thường
    text = text.lower()
    # Loại bỏ dấu câu
    text = re.sub(f"[{re.escape(string.punctuation)}]", "", text)
    # Loại bỏ khoảng trắng thừa
    text = re.sub(r'\s+', ' ', text).strip()
    # Tách văn bản thành các từ (tokens)
    tokens = text.split()
    # Đếm tổng số từ ban đầu
    total_tokens = len(tokens)
    # Loại bỏ các từ thuộc danh sách stop words
    tokens = [token for token in tokens if token not in stop_words]
    # Tính phần trăm các từ stop words đã bị loại bỏ
    removed_stop_words_percent = (total_tokens - len(tokens)) / total_tokens * 100
    # Trả về văn bản đã được xử lý và phần trăm từ stop words đã bị loại bỏ
    return ' '.join(tokens), removed_stop_words_percent
```


```python
# Danh sách chứa các văn bản đã qua tiền xử lý
processed_texts = []
# Danh sách chứa phần trăm các từ stop words đã bị loại bỏ trong từng văn bản
sum_stop_words_percents = 0
```


```python
# Sử dụng tqdm để hiển thị thanh tiến trình khi xử lý các văn bản
tqdm_iter = tqdm(texts, desc="Processing texts")
```


    Processing texts:   0%|          | 0/12000 [00:00<?, ?it/s]



```python
# Lặp qua từng văn bản trong danh sách văn bản gốc
for i, text in enumerate(tqdm_iter):
    # Tiền xử lý văn bản và tính phần trăm từ stop words đã bị loại bỏ
    processed_text, stop_words_percent = preprocess_text(text)
    # Thêm văn bản đã qua tiền xử lý vào danh sách
    processed_texts.append(processed_text)
    # Thêm phần trăm từ stop words đã bị loại bỏ vào danh sách
    sum_stop_words_percents += stop_words_percent
    # Tính phần trăm trung bình của các từ stop words đã bị loại bỏ
    avg_stop_words_percent = sum_stop_words_percents / (i+1)
    # Cập nhật thanh tiến trình với phần trăm trung bình hiện tại
    tqdm_iter.set_postfix({"avg_stop_words_percent": f"{avg_stop_words_percent:.2f}%"})
```


```python
# Cập nhật danh sách văn bản gốc với các văn bản đã qua tiền xử lý
texts = processed_texts
# Tính phần trăm trung bình cuối cùng của các từ stop words đã bị loại bỏ
average_stop_words_percent = sum_stop_words_percents / len(texts)
```


```python
# In ra phần trăm trung bình của các từ stop words đã bị loại bỏ
print(f"Average percentage of stop words removed: {average_stop_words_percent:.2f}%")
```

    Average percentage of stop words removed: 18.35%



```python
print("Văn bản sau sử lý: ", texts[0])
print("Nhãn của văn bản: ", labels[0])
```

    Văn bản sau sử lý:  nsnd minh hòa nghỉ hưu miệt mài đi dạy truyền năng lượng tích cực ở tuổi 60 5 năm nghỉ hưu nsnd minh hòa miệt mài đi giảng dạy tham gia bộ phim truyền đi năng lượng tích cực ở tuổi 60 nsnd minh hòa sinh năm 1964 trong gia đình truyền thống nghệ thuật ở hà nội chị học trường sân khấu điện ảnh khóa 19811986 thời gian dài công tác nhà hát kịch hà nội nghỉ hưu năm 2019 nữ nghệ sĩ năm giữ vị trí phó giám đốc nhà hát nsnd minh hòa năm 18 tuổi sở hữu vẻ đẹp đài sắc sảo nsnd minh hòa ghi dấu ấn ở tuyến nhân vật chính diện phản diện dù dạng vai nào bi hài ác thậm chí vai thật hiền lành mình yêu nhân vật say mê sống hết mình nhân vật mới hình hài nhân vật mình muốn đóng chị chia sẻ trong chương trình đẹp việt nữ nghệ sĩ nói chị đóng vai ác ham học hỏi đọc quan sát cuộc sống lẽ nsnd minh hòa ấn tượng đặc biệt vai trùm ma túy bạch yến đa mưu ghê gớm trong phim truyền hình cuồng phong gây sốt màn ảnh chị nghĩ đóng vai ác thế đường chắc mọi người ghét ném đá lắm cuối hóa thân xuất sắc mình nsnd minh hòa trao giải diễn viên yêu thích nhất truyền hình năm 2011 mc đọc đến tên mình tôi ù tai nghĩ mình giải nghĩ vai ác thế người xem bình chọn minh hoà tôi vô cảm ơn khán giả họ biết đâu nghệ sĩ đâu nhân vật nữ nsnd chia sẻ trong một bài trả lời phỏng vấn vietnamnet nsnd trung hiếu giám đốc nhà hát kịch hà nội nhận xét về đồng nghiệp trong chương trình đẹp việt nói chị một người phụ nữ tuyệt vời tuyệt vời trong cách sống anh em bạn bè cách ứng xử đồng nghiệp lần bước sân khấu tôi thấy ở chị ngọn lửa ngùn ngụt đam mê nghệ thuật nghề nghiệp nsnd minh hòa biến hóa dạng vai cuồng phong nsnd minh hòa liên tục biến hóa vai diễn ấn tượng trong chủ tịch tỉnh đàn chim trở về tuổi thanh xuân trò đời gió miền tối sáng nhà cửa sổ người năm gần nsnd minh hòa vai bà mẹ quyền lực sang chảnh nhập vai một bà mẹ đồng bóng hợm thích khoe mẽ trong tình yêu tham vọng thương ngày nắng về mới nhất món quà cha chính yêu nghề dù nghỉ hưu nsnd minh hòa bận rộn dự án phim công tác giảng dạy diễn xuất lứa sinh viên ở đại học sân khấu điện ảnh còn vướng bận công quản lý ở nhà hát nữ nghệ sĩ thời gian dành đam mê riêng nsnd minh hòa luôn chỉn chu về mặt hình ảnh kể tấm hình đăng mạng xã hội hay chọn đăng báo biến hóa phim vai diễn đa dạng ngoài đời nữ nghệ sĩ gần dùng tới trang sức phong cách giản dị nhẹ nhàng lần đăng ảnh facebook khán giả khen minh hòa trẻ lâu nsnd minh hòa tuổi 60 phong cách trẻ trung trong một bài trả lời phỏng vấn vietnamnet nsnd minh hòa bày tỏ bí quyết tôi nào hồn nhiên thoải mái chan hòa vui vẻ giận lâu to biến thành bé chính niềm vui mình công mọi người nói tôi nghỉ hưu bận rộn hơn đi làm hơn thực hơn 10 năm làm phó giám đốc nhà hát kịch hà nội tôi làm phim đi đâu xin phép hơn mình đi anh em nghệ sĩ đi suốt ngày tôi ở cơ quan dám đi đâu giờ nghỉ hưu giám đốc mình nhân viên mình thích làm tự xếp lịch tôi làm chủ thời gian lẫn sức khỏe bản thân cảm nhận cuộc sống an yên hơn chính tự chủ thời gian làm liên tục tôi thấy mình trẻ hơn thực tế tôi thường xếp lịch gạt bớt đi trộm vía công luôn kín lịch nsnd minh hòa thoải mái chia sẻ hình ảnh về bản thân hay dự án tham gia luôn kín tiếng về đời tư tuyệt đối đăng bức ảnh gia đình nào trang cá nhân trả lời vietnamnet thời điểm phim thương ngày nắng về sóng nsnd minh hòa biết con trai chị về việt nam làm lập gia đình tiết lộ thêm hình ảnh mới nhất nsnd minh hòa hiện minh hòa sống chồng gia đình con trai ở hà nội thường ngày chị tự lái xe đi dạy đi làm đi diễn chị dành phần lớn thời gian gia đình thích đạp xe đi chợ ở nhà nấu nướng chị thế hạnh phúc
    Nhãn của văn bản:  Xã hội



```python
"""## Huấn luyện và đánh giá các mô hình truyền thống

### Tạo dữ liệu huấn luyện và kiểm thử cho các mô hình truyền thống
"""
```




    '## Huấn luyện và đánh giá các mô hình truyền thống\n\n### Tạo dữ liệu huấn luyện và kiểm thử cho các mô hình truyền thống\n'




```python
# Khai báo mảng label y
y = np.array(labels)
```


```python
# Chia dữ liệu thành tập huấn luyện và tập kiểm tra
texts_train, texts_test, y_train, y_test = train_test_split(texts, y, test_size=0.2, stratify=y, random_state=42)
```


```python
# Encode labels
le = LabelEncoder()
y_train_enc = le.fit_transform(y_train)
y_test_enc = le.transform(y_test)
```


```python
print("Nhãn gốc: ", y_train[:5])
print("Nhãn sau khi mã hóa: ", y_train_enc[:5])
```

    Nhãn gốc:  ['Đời sống' 'Thời sự' 'Thế giới' 'Đời sống' 'Kinh tế']
    Nhãn sau khi mã hóa:  [10  8  6 10  3]



```python
# Shuffle the training data
texts_train, y_train_enc = shuffle(texts_train, y_train_enc, random_state=42)
```


```python
# Vectorize texts using TF-IDF for SVM
tfidf_vectorizer = TfidfVectorizer(max_features=5000, tokenizer=lambda x: x, preprocessor=lambda x: x, token_pattern=None)
X_train_tfidf = tfidf_vectorizer.fit_transform(texts_train)
X_test_tfidf = tfidf_vectorizer.transform(texts_test)
```


```python
print("Kích thức của tập train: ", X_train_tfidf.shape)
```

    Kích thức của tập train:  (9600, 182)



```python
"""### Khởi tạo, huấn luyện và đánh giá các mô hình truyền thống

Mô hình Naive Bayes
"""
```




    '### Khởi tạo, huấn luyện và đánh giá các mô hình truyền thống\n\nMô hình Naive Bayes\n'




```python
# Naive Bayes model
nb_model = MultinomialNB(alpha=1.0)
```


```python
# Fit dữ liệu
nb_model.fit(X_train_tfidf, y_train_enc)
```




<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">MultinomialNB</label><div class="sk-toggleable__content"><pre>MultinomialNB()</pre></div></div></div></div></div>




```python
# Dự đoán
y_pred_enc_nb = nb_model.predict(X_test_tfidf)
y_pred_nb = le.inverse_transform(y_pred_enc_nb)
```


```python
# Báo cáo phân loại cho Naive Bayes
report_nb = classification_report(y_test, y_pred_nb, output_dict=True, zero_division=0)
```


```python
"""Mô hình Logistic Regression"""
```




    'Mô hình Logistic Regression'




```python
### YOUR START CODE HERE ###
# Logistic Regression model
lr_model = LogisticRegression(max_iter=1000)
```


```python
# Fit dữ liệu
lr_model.fit(X_train_tfidf, y_train_enc)
```




<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-2" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox" checked><label for="sk-estimator-id-2" class="sk-toggleable__label sk-toggleable__label-arrow">LogisticRegression</label><div class="sk-toggleable__content"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>




```python
# Dự đoán
y_pred_enc_lr = lr_model.predict(X_test_tfidf)
y_pred_lr = le.inverse_transform(y_pred_enc_lr)
```


```python
# Báo cáo phân loại cho Logistic Regression
report_lr = classification_report(y_test, y_pred_lr, output_dict=True, zero_division=0)
### YOUR END CODE HERE ###
```


```python
"""Mô hình Random Forest"""
```




    'Mô hình Random Forest'




```python
### YOUR START CODE HERE ###
# Random Forest model
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
```


```python
# Fit dữ liệu
rf_model.fit(X_train_tfidf, y_train_enc)
# Dự đoán
y_pred_enc_rf = rf_model.predict(X_test_tfidf)
y_pred_rf = le.inverse_transform(y_pred_enc_rf)
```


```python
# Báo cáo phân loại cho Logistic Regression
report_rf = classification_report(y_test, y_pred_rf, output_dict=True, zero_division=0)
### YOUR END CODE HERE ###
```


```python
"""Mô hình SVM"""
```




    'Mô hình SVM'




```python
### YOUR START CODE HERE ###
# SVM model
svc_model = SVC(kernel='linear')
```


```python
# Fit dữ liệu
svc_model.fit(X_train_tfidf, y_train_enc)
# Dự đoán
y_pred_enc_svc = svc_model.predict(X_test_tfidf)
y_pred_svc = le.inverse_transform(y_pred_enc_svc)
```


```python
# Báo cáo phân loại cho Logistic Regression
report_svc = classification_report(y_test, y_pred_svc, output_dict=True, zero_division=0)
### YOUR END CODE HERE ###
```


```python
"""### Vẽ biểu đồ"""
```




    '### Vẽ biểu đồ'




```python
# Tạo danh sách các báo cáo phân loại
reports = {
    'Naive Bayes': report_nb,
    'Logistic Regression': report_lr,
    'Random Forest': report_rf,
    'SVC': report_svc
}
```


```python
fig, axs = plt.subplots(2, 2, figsize=(16, 16))
fig_cm, axs_cm = plt.subplots(2, 2, figsize=(16, 16))
```


    
![png](th%E1%BB%B1c_h%C3%A0nh_ph%C3%A2n_lo%E1%BA%A1i_tin_t%E1%BB%A9c_%28cnn%2C_rnn%2C_lstm%29_files/th%E1%BB%B1c_h%C3%A0nh_ph%C3%A2n_lo%E1%BA%A1i_tin_t%E1%BB%A9c_%28cnn%2C_rnn%2C_lstm%29_68_0.png)
    



    
![png](th%E1%BB%B1c_h%C3%A0nh_ph%C3%A2n_lo%E1%BA%A1i_tin_t%E1%BB%A9c_%28cnn%2C_rnn%2C_lstm%29_files/th%E1%BB%B1c_h%C3%A0nh_ph%C3%A2n_lo%E1%BA%A1i_tin_t%E1%BB%A9c_%28cnn%2C_rnn%2C_lstm%29_68_1.png)
    



```python
for i, (name, report) in enumerate(reports.items()):
    categories = list(report.keys())[:-3]  # exclude 'accuracy', 'macro avg', 'weighted avg'
    precisions = [report[cat]['precision'] for cat in categories]
    recalls = [report[cat]['recall'] for cat in categories]
    f1_scores = [report[cat]['f1-score'] for cat in categories]

    # In ra các thông số
    print(f'\n{name} Metrics:')
    for category in categories:
        print(f"{category}: Precision={report[category]['precision']:.2f}, Recall={report[category]['recall']:.2f}, F1-Score={report[category]['f1-score']:.2f}")

    # In ra độ chính xác trung bình
    accuracy = report['accuracy']
    print(f'Overall Accuracy: {accuracy:.2f}')

    # Vẽ biểu đồ đường
    axs[i // 2, i % 2].plot(categories, precisions, marker='o', label='Precision', color='blue')
    axs[i // 2, i % 2].plot(categories, recalls, marker='o', label='Recall', color='green')
    axs[i // 2, i % 2].plot(categories, f1_scores, marker='o', label='F1-Score', color='red')
    axs[i // 2, i % 2].set_ylim(0, 1)  # Đặt giới hạn trục y từ 0 đến 1
    axs[i // 2, i % 2].set_title(f'{name} Metrics')
    axs[i // 2, i % 2].set_ylabel('Score')
    axs[i // 2, i % 2].legend()
    axs[i // 2, i % 2].tick_params(axis='x', rotation=45)

    # Vẽ ma trận nhầm lẫn
    if name == 'Naive Bayes':
        cm = confusion_matrix(y_test, y_pred_nb, labels=le.classes_)
    elif name == 'Logistic Regression':
        cm = confusion_matrix(y_test, y_pred_lr, labels=le.classes_)
    elif name == 'Random Forest':
        cm = confusion_matrix(y_test, y_pred_rf, labels=le.classes_)
    elif name == 'SVC':
        cm = confusion_matrix(y_test, y_pred_svc, labels=le.classes_)

    sns.heatmap(cm, annot=True, fmt='d', xticklabels=le.classes_, yticklabels=le.classes_, cmap='Blues', ax=axs_cm[i // 2, i % 2])
    axs_cm[i // 2, i % 2].set_title(f'{name} Confusion Matrix')
    axs_cm[i // 2, i % 2].set_xlabel('Predicted')
    axs_cm[i // 2, i % 2].set_ylabel('True')
```

    
    Naive Bayes Metrics:
    Giáo dục: Precision=0.83, Recall=0.65, F1-Score=0.73
    Giải trí: Precision=0.47, Recall=0.32, F1-Score=0.38
    KHCN: Precision=0.39, Recall=0.53, F1-Score=0.45
    Kinh tế: Precision=0.46, Recall=0.47, F1-Score=0.47
    Pháp luật: Precision=0.65, Recall=0.74, F1-Score=0.69
    Sức khỏe: Precision=1.00, Recall=0.01, F1-Score=0.01
    Thế giới: Precision=0.76, Recall=0.74, F1-Score=0.75
    Thể thao: Precision=0.84, Recall=0.76, F1-Score=0.80
    Thời sự: Precision=0.53, Recall=0.38, F1-Score=0.44
    Xã hội: Precision=0.39, Recall=0.47, F1-Score=0.43
    Đời sống: Precision=0.31, Recall=0.66, F1-Score=0.42
    Overall Accuracy: 0.52
    
    Logistic Regression Metrics:
    Giáo dục: Precision=0.69, Recall=0.82, F1-Score=0.75
    Giải trí: Precision=0.53, Recall=0.40, F1-Score=0.46
    KHCN: Precision=0.46, Recall=0.49, F1-Score=0.47
    Kinh tế: Precision=0.59, Recall=0.44, F1-Score=0.51
    Pháp luật: Precision=0.60, Recall=0.71, F1-Score=0.65
    Sức khỏe: Precision=0.73, Recall=0.64, F1-Score=0.68
    Thế giới: Precision=0.72, Recall=0.75, F1-Score=0.74
    Thể thao: Precision=0.74, Recall=0.87, F1-Score=0.80
    Thời sự: Precision=0.49, Recall=0.49, F1-Score=0.49
    Xã hội: Precision=0.48, Recall=0.44, F1-Score=0.46
    Đời sống: Precision=0.51, Recall=0.54, F1-Score=0.52
    Overall Accuracy: 0.60


    
    Random Forest Metrics:
    Giáo dục: Precision=0.86, Recall=0.89, F1-Score=0.87
    Giải trí: Precision=0.52, Recall=0.55, F1-Score=0.53
    KHCN: Precision=0.60, Recall=0.62, F1-Score=0.61
    Kinh tế: Precision=0.69, Recall=0.54, F1-Score=0.60
    Pháp luật: Precision=0.67, Recall=0.80, F1-Score=0.73
    Sức khỏe: Precision=0.80, Recall=0.79, F1-Score=0.79
    Thế giới: Precision=0.76, Recall=0.79, F1-Score=0.77
    Thể thao: Precision=0.85, Recall=0.96, F1-Score=0.90
    Thời sự: Precision=0.61, Recall=0.61, F1-Score=0.61
    Xã hội: Precision=0.66, Recall=0.54, F1-Score=0.59
    Đời sống: Precision=0.60, Recall=0.56, F1-Score=0.58
    Overall Accuracy: 0.69
    
    SVC Metrics:
    Giáo dục: Precision=0.88, Recall=0.77, F1-Score=0.82
    Giải trí: Precision=0.47, Recall=0.55, F1-Score=0.51
    KHCN: Precision=0.44, Recall=0.59, F1-Score=0.50
    Kinh tế: Precision=0.66, Recall=0.43, F1-Score=0.52
    Pháp luật: Precision=0.61, Recall=0.70, F1-Score=0.65
    Sức khỏe: Precision=0.77, Recall=0.62, F1-Score=0.69
    Thế giới: Precision=0.76, Recall=0.74, F1-Score=0.75
    Thể thao: Precision=0.84, Recall=0.86, F1-Score=0.85
    Thời sự: Precision=0.51, Recall=0.46, F1-Score=0.48
    Xã hội: Precision=0.42, Recall=0.52, F1-Score=0.46
    Đời sống: Precision=0.59, Recall=0.50, F1-Score=0.54
    Overall Accuracy: 0.61



```python
plt.tight_layout()
plt.show()
plt.savefig('traditional-ml-models.png')
```


    <Figure size 640x480 with 0 Axes>



    <Figure size 640x480 with 0 Axes>



```python
# In ra nhãn dự đoán và nhãn thực tế
print("Nội dung bài báo: ", texts_train[0])
print("Nhãn dự đoán:" , le.inverse_transform(rf_model.predict(X_test_tfidf[:1])))
print("Nhãn thực tế: ", le.inverse_transform(y_train_enc[:1]))
```

    Nội dung bài báo:  cơn đau ám ảnh nhổ răng khôn sót chân răng răng khôn mọc khó quá trình nhổ diễn dài đau đớn khiến anh đsđ 25 tuổi hà nội bỏ dở chân răng lấy anh chịu đựng cơn đau hành hạ một đêm tới hệ thống y tế thu cúc tci xử lý nỗi ám ảnh nhổ răng khôn anh đsđ 2 lần nhổ răng khôn mới thành công ảnh thu cúc tci anh đ một răng khôn khá lâu răng mọc ngầm lệch ở phía hàm dẫn tới tình trạng đau nhức ảnh hưởng tới sinh hoạt hàng ngày anh quyết định đi nhổ bỏ răng một nha khoa gần nhà phương pháp anh lựa chọn nhổ răng khôn bằng kìm chi phí thấp hơn tuy nhiên quá trình nhổ răng diễn mấy suôn sẻ vị trí răng mọc khá sâu lệch nha sĩ mở xương chia cắt thân răng thành mảnh đưa ngoài quá trình nhổ diễn quá lâu đau đớn dù anh đ tiêm thuốc tê sợ hãi anh đ thể chịu nổi bỏ về trong còn 1 phần răng nằm phía sâu bên lấy ca nhổ răng tôi thể ăn mất ngủ đêm đau đớn ê nhức dồn dập sáng hôm tôi quyết định tới khoa răng hàm mặt hệ thống y tế thu cúc tci tư vấn anh nói dọn sạch chân răng khôn công nghệ piezotome trong 10 phút anh đsđ đến thu cúc tci kiểm tra xử lý dứt điểm chân răng còn sót ảnh tci khoa răng hàm mặt tci thăm khám chụp xquang răng bác sĩ nhận định một ca răng khôn mọc khó nhất còn phần chân răng nằm sâu bên trong bác sĩ tư vấn anh đ nhổ bằng máy phẫu thuật siêu âm piezotome phần chân răng khôn còn sót anh đ bác sĩ lấy ảnh tci bác sĩ đỗ tú anh trưởng khoa răng hàm mặt bệnh viện đa khoa quốc tế đkqt thu cúc tci piezotome công nghệ mới hiện đại thường định trong nhổ răng khôn nhất ca răng khôn mọc khó mọc lệch mọc ngầm mọc kẹt… phương pháp dùng sóng siêu âm mở nướu cắt tạo hình khung xương nâng xoang hàm xâm lấn tới mô mềm mũi khoan siêu mỏng rung sóng siêu âm tách mô mềm xung quanh chân răng quá trình nhổ giảm thiểu tối đa ma sát men răng hạn chế chảy máu sưng đau thêm piezotome kích thích tái tạo mô răng giúp quá trình lành thương diễn nhanh hơn hạn chế tối đa biến chứng khoảng 10 phút bác sĩ lấy phần chân răng còn sót lời khuyên bác sĩ ca răng khôn mọc khó bác sĩ đỗ tú anh chia sẻ thêm hiện nay 2 phương pháp nhổ răng khôn nhổ răng bằng phương pháp thông thường dùng kìm nhổ răng bằng phương pháp siêu âm piezotome ở phương pháp nhổ răng khôn bằng kìm bác sĩ dùng kìm động tác lắc làm đứt dây chằng khiến răng lung lay đưa ngoài tuy nhiên ở trường hợp răng mọc ngầm mọc lệch bác sĩ bộc lộ niêm mạc bằng dao mổ mở xương chia cắt thân răng chân răng lấy bằng bẩy răng khôn mọc khó quá trình nhổ diễn khó khăn hơn thể chảy máu tổn thương nguy cơ nhiễm trùng trong trường hợp bệnh nhân thể lựa chọn phương pháp piezotome bệnh nhân tới bệnh viện bác sĩ tư vấn đảm bảo an toàn mặc dù chi phí cao hơn song piezotome sở hữu ưu điểm quá trình nhổ đơn giản nhanh chóng khoảng 10 15 phút độ an toàn cao kiểm soát tối đa biến chứng vết thương nhổ răng nhanh lành bệnh nhân ít sưng nề đau nhức kiêng khem nhổ răng đơn giản piezotome bác sĩ tú anh biết bệnh nhân thể nhổ răng một máy phẫu thuật siêu âm piezotome đầu mũi khoan siêu mảnh làm đứt dây chằng xung quanh răng dễ dàng ảnh thu cúc tci
    Nhãn dự đoán: ['KHCN']
    Nhãn thực tế:  ['Sức khỏe']



```python
"""## Huấn luyện và đánh giá các mô hình học sâu

### Tạo dữ liệu huấn luyện và kiểm thử cho các mô hình học sâu

Tải mô hình phobert dùng để chuyển word thành vector
"""
```




    '## Huấn luyện và đánh giá các mô hình học sâu\n\n### Tạo dữ liệu huấn luyện và kiểm thử cho các mô hình học sâu\n\nTải mô hình phobert dùng để chuyển word thành vector\n'




```python
from torch import nn
from torch.utils.data import Dataset, DataLoader
from transformers import AutoTokenizer, AutoModel
```


```python
# Tải PhoBERT Tokenizer và Model
tokenizer = AutoTokenizer.from_pretrained('vinai/phobert-base')
embeder = AutoModel.from_pretrained('vinai/phobert-base')
```

    /home/ltpq/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
      warnings.warn(


    /usr/local/lib/python3.10/dist-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
      return self.fget.__get__(instance, owner)()



```python
# Chuyển mô hình sang GPU nếu có
embeder.to(device)
```




    RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(64001, 768, padding_idx=1)
        (position_embeddings): Embedding(258, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0-11): 12 x RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): RobertaPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )




```python
"""Hàm chuyển dãy word thành dãy vector"""
```




    'Hàm chuyển dãy word thành dãy vector'




```python
# Chuyển đổi từ thành vector.
def encode_texts(texts, tokenizer, embeder, max_length=256):
    encoded_texts = []  # Danh sách để lưu văn bản sau khi mã hóa.

    for text in tqdm(texts, desc="Chuyển từ thành vector"):
        # Chuyển văn bản thành các tensor đầu vào cho mô hình, cắt hoặc padding đến độ dài tối đa.
        inputs = tokenizer(text, return_tensors="pt", max_length=max_length, truncation=True, padding="max_length").to(device)

        # Không tính gradient vì chỉ thực hiện suy luận (inference), không huấn luyện.
        with torch.no_grad():
            outputs = embeder(**inputs)  # Truyền các tensor đầu vào qua mô hình để lấy các vector mã hóa.

        # Lấy vector mã hóa từ `last_hidden_state` và loại bỏ chiều batch.
        encoded_texts.append(outputs.last_hidden_state.squeeze(0))

    # Chuyển danh sách các tensor thành một tensor duy nhất.
    return torch.stack(encoded_texts)
```


```python
test = ["Xin chào", "Đây là chương trình AI4E"]
encode_texts(test, tokenizer, embeder).shape
```


    Chuyển từ thành vector:   0%|          | 0/2 [00:00<?, ?it/s]





    torch.Size([2, 256, 768])




```python
"""Chuyển đổi dữ liệu"""
```




    'Chuyển đổi dữ liệu'




```python
# Vectorize texts using phobert
X_train_phobert = encode_texts(texts_train, tokenizer, embeder)
X_test_phobert = encode_texts(texts_test, tokenizer, embeder)
```


    Chuyển từ thành vector:   0%|          | 0/9600 [00:00<?, ?it/s]



    Chuyển từ thành vector:   0%|          | 0/2400 [00:00<?, ?it/s]



```python
"""Tạo Dataloader"""
```




    'Tạo Dataloader'




```python
# Khai báo lớp dùng để tạo dataset
class TextDataset(Dataset):
    def __init__(self, texts, labels):
        self.texts = texts
        self.labels = labels

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        return self.texts[idx], self.labels[idx]
```


```python
# Tạo Dataset cho tập huấn luyện và tập kiểm thử
train_dataset = TextDataset(X_train_phobert, y_train_enc)
test_dataset = TextDataset(X_test_phobert, y_test_enc)
```


```python
# Tạo DataLoader cho tập huấn luyện và tập kiểm thử
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)
```


```python
"""### Định nghĩa các lớp mô hình học sâu"""
```




    '### Định nghĩa các lớp mô hình học sâu'




```python
# Xây dựng mô hình RNN
class RNNClassifier(nn.Module):
    def __init__(self, input_size, hidden_size, output_size, num_layers=1):
        super(RNNClassifier, self).__init__()
        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)
        self.num_layers = num_layers

    def forward(self, x):
        h0 = torch.zeros(self.num_layers, x.size(0), hidden_size).to(x.device)
        out, _ = self.rnn(x, h0)
        out = self.fc(out[:, -1, :])
        return out
```


```python
# Xây dựng mô hình LSTM
class LSTMClassifier(nn.Module):
    def __init__(self, input_size, hidden_size, output_size, num_layers=1):
        super(LSTMClassifier, self).__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)
        self.num_layers = num_layers

    def forward(self, x):
        h0 = torch.zeros(self.num_layers, x.size(0), hidden_size).to(x.device)
        c0 = torch.zeros(self.num_layers, x.size(0), hidden_size).to(x.device)
        out, _ = self.lstm(x, (h0, c0))
        out = self.fc(out[:, -1, :])
        return out
```


```python
# Xây dựng mô hình CNN
class CNNClassifier(nn.Module):
    def __init__(self, input_size, output_size, num_filters, kernel_size, max_length=256):
        super(CNNClassifier, self).__init__()
        self.conv1 = nn.Conv1d(in_channels=input_size, out_channels=num_filters, kernel_size=kernel_size)
        self.pool = nn.MaxPool1d(kernel_size=max_length - kernel_size + 1)
        self.fc = nn.Linear(num_filters, output_size)

    def forward(self, x):
        x = x.permute(0, 2, 1)  # Đổi thứ tự để phù hợp với Conv1d (batch_size, input_size, max_length)
        x = self.conv1(x)
        x = self.pool(x).squeeze(2)
        x = self.fc(x)
        return x
```


```python
class CNNClassifier(nn.Module):
    def __init__(self, input_size, output_size, num_filters, kernel_size, max_length=256):
        super(CNNClassifier, self).__init__()

        self.conv1 = nn.Conv1d(in_channels=input_size, out_channels=num_filters, kernel_size=kernel_size)
        self.bn1 = nn.BatchNorm1d(num_filters)
        self.conv2 = nn.Conv1d(in_channels=num_filters, out_channels=num_filters*2, kernel_size=kernel_size)
        # self.bn2 = nn.BatchNorm1d(num_filters*2)
        self.pool = nn.MaxPool1d(kernel_size=2)
        self.drop = nn.Dropout(p=0.5)
        self.fc1 = nn.Linear(num_filters*2 * ((max_length - 2*(kernel_size-1)) // 2), 256)
        self.fc2 = nn.Linear(256, output_size)

    def forward(self, x):
        x = x.permute(0, 2, 1)  # Adjust input dimensions for Conv1d
        x = torch.relu(self.bn1(self.conv1(x)))
        x = torch.relu(self.conv2(x))
        x = self.pool(x)
        x = self.drop(x)
        x = x.view(x.size(0), -1)  # Flatten the tensor
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x
```


```python
"""### Khai báo các mô hình học sâu"""
```




    '### Khai báo các mô hình học sâu'




```python
# Thiết lập các thông số
input_size = 768  # Kích thước của vector ẩn PhoBERT
output_size = len(le.classes_) # Số lượng lớp
```


```python
### YOUR START CODE HERE ###
hidden_size = 512
num_filters = 10
kernel_size = 5
### YOUR END CODE HERE ###
```


```python
# Khởi tạo các mô hình
deep_models = {
    'CNN': CNNClassifier(input_size, output_size, num_filters, kernel_size, max_length=256).to(device),
    'RNN': RNNClassifier(input_size, hidden_size, output_size, num_layers=3).to(device),
    'LSTM': LSTMClassifier(input_size, hidden_size, output_size, num_layers=1).to(device),
}
```


```python
"""### Huấn luyện và đánh giá các mô hình học sâu"""
```




    '### Huấn luyện và đánh giá các mô hình học sâu'




```python
# Hàm huấn luyện và đánh giá mô hình
def train_and_evaluate(model, train_loader, test_loader, num_epochs=10, criterion=None, optimizer_fn=None, scheduler_fn=None):
    # Khởi tạo optimizer
    optimizer = optimizer_fn(model.parameters())

    # Khởi tạo scheduler
    scheduler = scheduler_fn(optimizer)

    for epoch in range(num_epochs):
        model.train()
        for texts, labels in train_loader:
            texts, labels = texts.to(device), labels.to(device)
            outputs = model(texts)
            loss = criterion(outputs, labels)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

        if scheduler is not None:
            scheduler.step()

        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}")

    model.eval()
    all_preds = []
    all_labels = []
    with torch.no_grad():
        for texts, labels in test_loader:
            texts, labels = texts.to(device), labels.to(device)
            outputs = model(texts)
            _, preds = torch.max(outputs, 1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    return all_labels, all_preds
```


```python
"""Lựa chọn criterion, optimizer, và scheduler"""
```




    'Lựa chọn criterion, optimizer, và scheduler'




```python
### YOUR START CODE HERE ###
# Khai báo criterion
criterion = nn.CrossEntropyLoss()
```


```python
# Hàm tạo optimizer
def optimizer_fn(params):
   return torch.optim.Adam(params, lr=0.001)
```


```python
# Hàm tạo scheduler
def scheduler_fn(optimizer):
    return torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)
```


```python
num_epochs = 20
### YOUR START CODE HERE ###
```


```python
"""### Vẽ biểu đồ"""
```




    '### Vẽ biểu đồ'




```python
# Hình vẽ kết quả của mô hình sau khi train
fig, axs = plt.subplots(2, 2, figsize=(16, 16))
fig_cm, axs_cm = plt.subplots(2, 2, figsize=(16, 16))
```


    
![png](th%E1%BB%B1c_h%C3%A0nh_ph%C3%A2n_lo%E1%BA%A1i_tin_t%E1%BB%A9c_%28cnn%2C_rnn%2C_lstm%29_files/th%E1%BB%B1c_h%C3%A0nh_ph%C3%A2n_lo%E1%BA%A1i_tin_t%E1%BB%A9c_%28cnn%2C_rnn%2C_lstm%29_102_0.png)
    



    
![png](th%E1%BB%B1c_h%C3%A0nh_ph%C3%A2n_lo%E1%BA%A1i_tin_t%E1%BB%A9c_%28cnn%2C_rnn%2C_lstm%29_files/th%E1%BB%B1c_h%C3%A0nh_ph%C3%A2n_lo%E1%BA%A1i_tin_t%E1%BB%A9c_%28cnn%2C_rnn%2C_lstm%29_102_1.png)
    



```python
# Lưu trữ F1 scores của các mô hình
model_f1_scores = {}
```


```python
for i, (name, model) in enumerate(deep_models.items()):
    print(f"Training {name} model...")
    y_test, y_pred = train_and_evaluate(model, train_loader, test_loader, num_epochs,
                                        criterion=criterion, optimizer_fn=optimizer_fn, scheduler_fn=scheduler_fn)
    y_test = le.inverse_transform(y_test)
    y_pred = le.inverse_transform(y_pred)

    # Tạo báo cáo phân loại
    report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)
    categories = list(report.keys())[:-3]  # exclude 'accuracy', 'macro avg', 'weighted avg'

    # Tạo dữ liệu để vẽ biểu đồ
    precisions = [report[cat]['precision'] for cat in categories]
    recalls = [report[cat]['recall'] for cat in categories]
    f1_scores = [report[cat]['f1-score'] for cat in categories]
    model_f1_scores[name] = f1_scores

    # In ra các thông số
    print(f'\n{name} Metrics:')
    for category in categories:
        print(f"{category}: Precision={report[category]['precision']:.2f}, Recall={report[category]['recall']:.2f}, F1-Score={report[category]['f1-score']:.2f}")

    # In ra độ chính xác trung bình
    accuracy = report['accuracy']
    print(f'Overall Accuracy: {accuracy:.2f}\n')

    # Vẽ biểu đồ đường
    axs[i // 2, i % 2].plot(categories, precisions, marker='o', label='Precision', color='blue')
    axs[i // 2, i % 2].plot(categories, recalls, marker='o', label='Recall', color='green')
    axs[i // 2, i % 2].plot(categories, f1_scores, marker='o', label='F1-Score', color='red')
    axs[i // 2, i % 2].set_ylim(0, 1)  # Đặt giới hạn trục y từ 0 đến 1
    axs[i // 2, i % 2].set_title(f'{name} Metrics')
    axs[i // 2, i % 2].set_ylabel('Score')
    axs[i // 2, i % 2].legend()
    axs[i // 2, i % 2].tick_params(axis='x', rotation=45)

    # Vẽ ma trận nhầm lẫn
    cm = confusion_matrix(y_test, y_pred, labels=le.classes_)
    sns.heatmap(cm, annot=True, fmt='d', xticklabels=le.classes_, yticklabels=le.classes_, cmap='Blues', ax=axs_cm[i // 2, i % 2])
    axs_cm[i // 2, i % 2].set_title(f'{name} Confusion Matrix')
    axs_cm[i // 2, i % 2].set_xlabel('Predicted')
    axs_cm[i // 2, i % 2].set_ylabel('True')
```

    Training CNN model...


    Epoch [1/20], Loss: 1.1044


    Epoch [2/20], Loss: 0.6647


    Epoch [3/20], Loss: 0.6460


    Epoch [4/20], Loss: 0.5260


    Epoch [5/20], Loss: 0.7474


    Epoch [6/20], Loss: 0.2751


    Epoch [7/20], Loss: 0.2678


    Epoch [8/20], Loss: 0.2824


    Epoch [9/20], Loss: 0.1558


    Epoch [10/20], Loss: 0.1714


    Epoch [11/20], Loss: 0.2919


    Epoch [12/20], Loss: 0.2165


    Epoch [13/20], Loss: 0.3537


    Epoch [14/20], Loss: 0.1763


    Epoch [15/20], Loss: 0.2576


    Epoch [16/20], Loss: 0.3527


    Epoch [17/20], Loss: 0.1794


    Epoch [18/20], Loss: 0.2205


    Epoch [19/20], Loss: 0.2707


    Epoch [20/20], Loss: 0.0754


    
    CNN Metrics:
    Giáo dục: Precision=0.91, Recall=0.93, F1-Score=0.92
    Giải trí: Precision=0.80, Recall=0.79, F1-Score=0.79
    KHCN: Precision=0.80, Recall=0.77, F1-Score=0.78
    Kinh tế: Precision=0.77, Recall=0.72, F1-Score=0.74
    Pháp luật: Precision=0.86, Recall=0.90, F1-Score=0.88
    Sức khỏe: Precision=0.88, Recall=0.90, F1-Score=0.89
    Thế giới: Precision=0.89, Recall=0.87, F1-Score=0.88
    Thể thao: Precision=0.94, Recall=0.98, F1-Score=0.96
    Thời sự: Precision=0.68, Recall=0.71, F1-Score=0.69
    Xã hội: Precision=0.71, Recall=0.62, F1-Score=0.66
    Đời sống: Precision=0.66, Recall=0.71, F1-Score=0.69
    Overall Accuracy: 0.81
    
    Training RNN model...


    Epoch [1/20], Loss: 0.9787


    Epoch [2/20], Loss: 1.0192


    Epoch [3/20], Loss: 0.7727


    Epoch [4/20], Loss: 0.6359


    Epoch [5/20], Loss: 0.5264


    Epoch [6/20], Loss: 0.4237


    Epoch [7/20], Loss: 0.2944


    Epoch [8/20], Loss: 0.2526


    Epoch [9/20], Loss: 0.2807


    Epoch [10/20], Loss: 0.1719


    Epoch [11/20], Loss: 0.2332


    Epoch [12/20], Loss: 0.0821


    Epoch [13/20], Loss: 0.1018


    Epoch [14/20], Loss: 0.0558


    Epoch [15/20], Loss: 0.0828


    Epoch [16/20], Loss: 0.1142


    Epoch [17/20], Loss: 0.1108


    Epoch [18/20], Loss: 0.0934


    Epoch [19/20], Loss: 0.1191


    Epoch [20/20], Loss: 0.0639


    
    RNN Metrics:
    Giáo dục: Precision=0.89, Recall=0.89, F1-Score=0.89
    Giải trí: Precision=0.69, Recall=0.67, F1-Score=0.68
    KHCN: Precision=0.73, Recall=0.72, F1-Score=0.73
    Kinh tế: Precision=0.72, Recall=0.67, F1-Score=0.70
    Pháp luật: Precision=0.81, Recall=0.84, F1-Score=0.83
    Sức khỏe: Precision=0.88, Recall=0.89, F1-Score=0.88
    Thế giới: Precision=0.86, Recall=0.84, F1-Score=0.85
    Thể thao: Precision=0.93, Recall=0.96, F1-Score=0.94
    Thời sự: Precision=0.65, Recall=0.70, F1-Score=0.67
    Xã hội: Precision=0.57, Recall=0.52, F1-Score=0.55
    Đời sống: Precision=0.56, Recall=0.62, F1-Score=0.59
    Overall Accuracy: 0.75
    
    Training LSTM model...


    Epoch [1/20], Loss: 0.5949


    Epoch [2/20], Loss: 0.5417


    Epoch [3/20], Loss: 0.5531


    Epoch [4/20], Loss: 0.6408


    Epoch [5/20], Loss: 0.2968


    Epoch [6/20], Loss: 0.2143


    Epoch [7/20], Loss: 0.1232


    Epoch [8/20], Loss: 0.1761


    Epoch [9/20], Loss: 0.0651


    Epoch [10/20], Loss: 0.0727


    Epoch [11/20], Loss: 0.0429


    Epoch [12/20], Loss: 0.0533


    Epoch [13/20], Loss: 0.0646


    Epoch [14/20], Loss: 0.0857


    Epoch [15/20], Loss: 0.0459


    Epoch [16/20], Loss: 0.0253


    Epoch [17/20], Loss: 0.0903


    Epoch [18/20], Loss: 0.0801


    Epoch [19/20], Loss: 0.0277


    Epoch [20/20], Loss: 0.0296


    
    LSTM Metrics:
    Giáo dục: Precision=0.88, Recall=0.88, F1-Score=0.88
    Giải trí: Precision=0.71, Recall=0.73, F1-Score=0.72
    KHCN: Precision=0.73, Recall=0.66, F1-Score=0.70
    Kinh tế: Precision=0.68, Recall=0.69, F1-Score=0.69
    Pháp luật: Precision=0.84, Recall=0.83, F1-Score=0.83
    Sức khỏe: Precision=0.86, Recall=0.87, F1-Score=0.87
    Thế giới: Precision=0.85, Recall=0.86, F1-Score=0.86
    Thể thao: Precision=0.92, Recall=0.98, F1-Score=0.95
    Thời sự: Precision=0.66, Recall=0.67, F1-Score=0.66
    Xã hội: Precision=0.62, Recall=0.59, F1-Score=0.60
    Đời sống: Precision=0.62, Recall=0.64, F1-Score=0.63
    Overall Accuracy: 0.76
    



```python
# Vẽ F1 scores của cả 3 mô hình lên subplot thứ 4
for name, f1_scores in model_f1_scores.items():
    axs[1, 1].plot(categories, f1_scores, marker='o', label=f'{name} F1-Score')
axs[1, 1].set_ylim(0, 1)
axs[1, 1].set_title('F1 Scores Comparison')
axs[1, 1].set_ylabel('F1 Score')
axs[1, 1].legend()
axs[1, 1].tick_params(axis='x', rotation=45)
```


```python
plt.tight_layout()
plt.show()
plt.savefig('modern-dl-models.png')
```


    <Figure size 640x480 with 0 Axes>



    <Figure size 640x480 with 0 Axes>



```python
# In nhãn dự đoán và nhãn thực tế
print("Văn bản đầu vào: ", texts_test[0])
print("Nhãn dự đoán: ", y_pred[0])
print("Nhãn thực tế: ", y_test[0])
```

    Văn bản đầu vào:  tiết lộ mới về apple watch series 10 apple watch series 10 hai phiên bản kích thước lần lượt 44mm 49mm thay 41mm 45mm dự kiến thiết giới thiệu tháng 9 tới trong một bài đăng gần nhà phân tích mingchi kuo tiết lộ đồng hồ apple watch thế hệ tiếp thiết kế mỏng hơn màn hình kích thước lớn hơn phiên bản tiền nhiệm apple watch series 10 thiết kế mỏng hơn màn hình lớn hơn ảnh cnbc cụ thể apple watch series 10 hai phiên bản kích thước lần lượt 44mm 49mm thay 41mm 45mm dự kiến thiết giới thiệu tháng 9 tới thời điểm dòng iphone 16 trong thông số phần cứng apple watch ultra thế hệ mới giữ nguyên phiên bản tiền nhiệm khả năng apple giới thiệu thêm một phiên bản màu sắc mới dòng sản phẩm kuo biết thêm một số bộ phận đồng hồ thể sản xuất bằng công nghệ in 3d kuo bright laser technologies cung cấp bộ phận in 3d động thái nhằm giảm thời gian sản xuất tối ưu lượng nguyên vật liệu sử dụng kuo nói quá trình thử nghiệm cải thiện đáng kể hiệu quả sản xuất đồng hồ
    Nhãn dự đoán:  KHCN
    Nhãn thực tế:  KHCN



```python
"""## Bài tập về nhà
Gán nhãn lại mục metadata.cat trong file text_no_cat.json, tải file đã gán nhãn lên trên github và nộp lại link.

Link file text_no_cat: https://github.com/nmquang003/AI4E/blob/main/test_news_no_cat.json

Link file categories: https://github.com/nmquang003/AI4E/blob/main/categories.txt

### Tải Test dataset
"""
```




    '## Bài tập về nhà\nGán nhãn lại mục metadata.cat trong file text_no_cat.json, tải file đã gán nhãn lên trên github và nộp lại link.\n\nLink file text_no_cat: https://github.com/nmquang003/AI4E/blob/main/test_news_no_cat.json\n\nLink file categories: https://github.com/nmquang003/AI4E/blob/main/categories.txt\n\n### Tải Test dataset\n'




```python
# URL trực tiếp đến file JSON thô trên GitHub
url = 'https://github.com/nmquang003/AI4E/blob/main/test_news_no_cat.json?raw=true'
```


```python
# Tải nội dung của file
response = requests.get(url)
```


```python
# Kiểm tra mã trạng thái phản hồi để đảm bảo rằng yêu cầu thành công
if response.status_code == 200:
    try:
        data = response.json()  # Đọc nội dung file JSON
        # Hiển thị phần tử đầu tiên của file JSON
        if isinstance(data, list) and len(data) > 0:
            pprint(json.dumps(data[0], indent=4, ensure_ascii=False))
        else:
            print("Dữ liệu JSON không phải là một danh sách hoặc danh sách trống.")

    except json.JSONDecodeError as e:
        print("JSONDecodeError: Không thể phân tích nội dung JSON.")
        print("Nội dung phản hồi không phải là JSON hợp lệ:")
        print(response.text)  # In ra nội dung phản hồi để kiểm tra
else:
    print(f"Yêu cầu thất bại với mã trạng thái {response.status_code}")
    print("Nội dung phản hồi:", response.text)
```

    ('{\n'
     '    "url": null,\n'
     '    "title": "Nhiều tháng đóng bảo hiểm xã hội bỗng \\"biến mất\\" trên ứng '
     'dụng quản lý",\n'
     '    "description": "Một số người lao động truy cập vào tài khoản bảo hiểm xã '
     'hội (BHXH) số - VssID thì thấy quá trình tham gia của mình \\"biến mất\\" '
     'nhiều tháng.",\n'
     '    "content": "Chị Ngọc Phương tham gia BHXh tự nguyện từ tháng 12/2021. '
     'Bắt đầu từ tháng 11/2023 đến nay, chị Phương tham gia BHXH bắt buộc tại công '
     'ty. Tuy nhiên, khi truy cập tài khoản VssID, chị Phương không thấy quá trình '
     'tham gia BHXH của mình được cập nhật.\\nCũng giống Phương, chị Thanh Tuyền '
     'tham gia BHXH từ tháng 7/2017 đến nay, trải qua 3 công ty và có 2 giai đoạn '
     'tạm ngừng tham gia. Tuy nhiên, khi truy cập tài khoản VssID, chị Tuyền phát '
     'hiện quá trình tham gia của mình thiếu mất giai đoạn làm việc ở công ty thứ '
     '2, kéo dài từ tháng 9/2021 đến tháng 3/2022.\\nMới đây, anh Tuấn (làm việc '
     'tại một công ty dịch vụ công ích ở TPHCM) truy cập tài khoản VssID cũng thấy '
     'thiếu quá trình đóng BHXH từ tháng 8/2007 đến tháng 4/2009. Trong khi đó, '
     'trên tờ rời sổ BHXH bản giấy của anh Tuấn có quá trình này.\\nChị Thanh Uyên '
     'bắt đầu đi làm và tham gia BHXH từ tháng 4/2007 đến nay, trải qua 7 công ty. '
     'Tuy nhiên, trên tài khoản VssID của chị không ghi nhận quá trình tham gia '
     'BHXH ở bất cứ công ty nào.\\nChị Ngọc Phương lo lắng: \\"Nếu không có quá '
     'trình tham gia trên VssID, bây giờ tôi nghỉ việc thì có làm đơn xin hưởng '
     'bảo hiểm thất nghiệp được không?\\".\\nVssID vẫn còn nhiều trường hợp chưa '
     'cập nhật đầy đủ dữ liệu tham gia BHXH của người lao động (Ảnh minh họa: Sơn '
     'Nguyễn).\\nVề trường hợp của chị Ngọc Phương, BHXH Việt Nam cho biết quá '
     'trình đóng của chị vẫn được ghi nhận trên hệ thống phần mềm của BHXH Việt '
     'Nam. Quá trình đóng BHXH của chị Phương từ tháng 11/2023 đến nay được ghi '
     'nhận đầy đủ 2 giai đoạn từ BHXH tự nguyện chuyển sang BHXH bắt buộc.\\nTheo '
     'BHXH Việt Nam, hiện nay trên ứng dụng VssID còn có trường hợp người lao động '
     'bị thiếu quá trình tham gia đóng BHXH.\\nĐể nhanh chóng cập nhật thông tin '
     'chính xác, khi phát hiện thiếu quá trình đóng, người lao động cần phản ánh '
     'ngay với cơ quan BHXH tỉnh, huyện hoặc BHXH Việt Nam (thông qua tổng đài hỗ '
     'trợ 19009068 hoặc thông qua Cổng Thông tin điện tử BHXH Việt Nam) để được hỗ '
     'trợ.\\nBHXH Việt Nam khẳng định toàn bộ quá trình tham gia BHXH, bảo hiểm y '
     'tế, bảo hiểm thất nghiệp của người lao động đã được số hóa, đồng bộ, lưu tại '
     'Cơ sở dữ liệu của ngành.\\nDo đó, người tham gia BHXH không cần quá lo lắng '
     'về việc hiển thị thiếu thời gian tham gia đóng BHXH trên ứng dụng VssID. '
     'Điều này không ảnh hưởng đến quyền lợi khi người lao động hưởng các chế độ '
     'BHXH.\\nBHXH Việt Nam đang đẩy mạnh các giải pháp để cập nhật đầy đủ dữ liệu '
     'về thời gian tham gia BHXH trên ứng dụng VssID cho người lao động trong thời '
     'gian sớm nhất.",\n'
     '    "metadata": {\n'
     '        "cat": null,\n'
     '        "subcat": null,\n'
     '        "published_date": null,\n'
     '        "author": null\n'
     '    },\n'
     '    "web_news": null\n'
     '}')



```python
"""### Làm sạch dữ liệu"""
```




    '### Làm sạch dữ liệu'




```python
texts = []
for article in data:
    text = article.get('title', '') + ' ' + article.get('description', '') + ' ' + article.get('content', '')
    texts.append(text)
```


```python
# Hàm tiền xử lý văn bản
def preprocess_text(text):
    text = text.lower()
    text = re.sub(f"[{re.escape(string.punctuation)}]", "", text)
    text = re.sub(r'\s+', ' ', text).strip()
    tokens = text.split()
    total_tokens = len(tokens)
    tokens = [token for token in tokens if token not in stop_words]
    removed_stop_words_percent = (total_tokens - len(tokens)) / total_tokens * 100
    return ' '.join(tokens), removed_stop_words_percent
```


```python
processed_texts = []
sum_stop_words_percents = 0
```


```python
# Sử dụng tqdm để hiển thị thanh tiến trình khi xử lý các văn bản
tqdm_iter = tqdm(texts, desc="Processing texts")
```


    Processing texts:   0%|          | 0/3755 [00:00<?, ?it/s]



```python
for i, text in enumerate(tqdm_iter):
    processed_text, stop_words_percent = preprocess_text(text)
    processed_texts.append(processed_text)
    sum_stop_words_percents += stop_words_percent
    avg_stop_words_percent = sum_stop_words_percents / (i+1)
    tqdm_iter.set_postfix({"avg_stop_words_percent": f"{avg_stop_words_percent:.2f}%"})
```


```python
# Cập nhật danh sách văn bản gốc với các văn bản đã qua tiền xử lý
texts = processed_texts
average_stop_words_percent = sum_stop_words_percents / len(texts)
```


```python
# In ra phần trăm trung bình của các từ stop words đã bị loại bỏ
print(f"Average percentage of stop words removed: {average_stop_words_percent:.2f}%")
```

    Average percentage of stop words removed: 18.65%



```python
"""### Tiền xử lý PhoBERT"""
```




    '### Tiền xử lý PhoBERT'




```python
X_test_phobert = encode_texts(texts_test, tokenizer, embeder)
```


    Chuyển từ thành vector:   0%|          | 0/2400 [00:00<?, ?it/s]



```python
class TestDataset(Dataset):
    def __init__(self, texts):
        self.texts = texts

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        return self.texts[idx]
```


```python
test_dataset = TestDataset(X_test_phobert)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)
```


```python
"""### Gán nhãn dữ liệu bằng mô hình"""
```




    '### Gán nhãn dữ liệu bằng mô hình'




```python
model = deep_models['LSTM']
model.eval()
```




    LSTMClassifier(
      (lstm): LSTM(768, 512, batch_first=True)
      (fc): Linear(in_features=512, out_features=11, bias=True)
    )




```python
all_preds = []
with torch.no_grad():
    for texts in test_loader:
        texts = texts.to(device)
        outputs = model(texts)
        _, preds = torch.max(outputs, 1)
        all_preds.extend(preds.cpu().numpy())
for i, pred in enumerate(all_preds):
    data[i]['metadata']['cat'] = le.inverse_transform([pred])[0]
```


```python
"""### Lưu kết quả"""
```




    '### Lưu kết quả'




```python
with open('labeled_data.json', 'w', encoding='utf-8') as f:
  json.dump(data, f, ensure_ascii=False, indent=4)
```

files.download('labeled_data.json')
